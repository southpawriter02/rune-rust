> **Archived** - This plan has been consolidated. See the complete version at [v0.3.13](../v0.3.x/v0.3.13.md).

Here is the comprehensive implementation plan for v0.3.13a: The Loot Audit.
This version provides the Monte Carlo simulation tools necessary to validate the game's economy. By running thousands of loot generation cycles in seconds, developers can verify that "Myth-Forged" items are appropriately rare and that the "Scrip" economy is balanced across different danger levels.

v0.3.13a: The Loot Audit
Goal: Implement LootAuditService and the audit-loot CLI command to simulate item drops, aggregate statistics, and generate a variance report comparing "Actual" drop rates against "Expected" probabilities.

1. Architecture & Data Flow
The Simulation Pipeline
	1	Trigger: Developer executes dotnet run -- --audit-loot iterations=10000 biome=Industrial danger=Hostile.
	2	Configuration: Program.cs parses arguments and invokes LootAuditService.
	3	Simulation Loop:
	◦	The service constructs a LootGenerationContext based on arguments.
	◦	It loops N times, calling ILootService.GenerateLoot(context).
	◦	Aggregation: Each result is fed into a LootStatistics accumulator which tracks counts by Rarity, ItemType, and TotalValue.
	4	Analysis:
	◦	Calculate percentages (e.g., "Myth-Forged dropped 0.4% of the time").
	◦	Compare against defined constants (e.g., Expected 0.5%).
	5	Reporting:
	◦	Generate a Markdown table summarizing the results.
	◦	Write to docs/audits/loot_audit_[timestamp].md.

2. Logic Decision Trees
A. Audit Loop Logic
Input: Iterations (N), Biome, DangerLevel
	1	Initialize: stats = new LootStatistics().
	2	Loop i = 0 to N:
	◦	context = CreateContext(Biome, Danger, PlayerLevel=1).
	◦	result = _lootService.GenerateLoot(context).
	◦	Record: stats.Add(result).
	▪	Increment TotalDrops.
	▪	Increment ValueSum += result.TotalValue.
	▪	For each item: Increment RarityCounts[item.Quality] and TypeCounts[item.Type].
	3	Finalize: Return stats.
B. Variance Analysis Logic
Input: LootStatistics
	1	Calculate Frequency: Actual % = (Count / TotalIterations) * 100.
	2	Determine Deviation: Delta = Actual % - Expected %.
	3	Flagging:
	◦	If Abs(Delta) > 5.0%: Mark as CRITICAL.
	◦	If Abs(Delta) > 1.0%: Mark as WARNING.
	◦	Else: Mark as OK.

3. Deliverable Checklist
	•	Core:
	◦	[ ] Define LootStatistics model to hold aggregation data.
	◦	[ ] Add ExpectedDropRates dictionary to LootTables (for comparison).
	•	Engine:
	◦	[ ] Implement LootAuditService.
	◦	[ ] Implement RunSimulationAsync method.
	◦	[ ] Implement GenerateReport method (Markdown builder).
	•	Terminal:
	◦	[ ] Update Program.cs to handle --audit-loot argument.
	◦	[ ] Add CLI parameter parsing for iterations, biome, and danger level.
	•	Project:
	◦	[ ] Create docs/audits/ directory.

4. Code Implementation
A. Core Layer (Statistics Model)
File: RuneAndRust.Core/Models/Analysis/LootStatistics.cs
public class LootStatistics
{
    public int TotalIterations { get; set; }
    public int TotalItemsDropped { get; set; }
    public long TotalScripValue { get; set; }
    public Dictionary<QualityTier, int> RarityCounts { get; } = new();
    public Dictionary<ItemType, int> TypeCounts { get; } = new();

    public void Record(LootResult result)
    {
        TotalIterations++;
        if (!result.Success) return;

        foreach (var item in result.Items)
        {
            TotalItemsDropped++;
            TotalScripValue += item.Value;

            if (!RarityCounts.ContainsKey(item.Quality)) RarityCounts[item.Quality] = 0;
            RarityCounts[item.Quality]++;

            if (!TypeCounts.ContainsKey(item.ItemType)) TypeCounts[item.ItemType] = 0;
            TypeCounts[item.ItemType]++;
        }
    }
}
B. Engine Layer (Audit Service)
File: RuneAndRust.Engine/Services/LootAuditService.cs
public class LootAuditService
{
    private readonly ILootService _lootService;
    private readonly ILogger _logger;

    public LootAuditService(ILootService lootService, ILogger logger)
    {
        _lootService = lootService;
        _logger = logger;
    }

    public async Task<string> RunAuditAsync(int iterations, BiomeType biome, DangerLevel danger)
    {
        _logger.LogInformation("Starting Loot Audit: {N} iterations in {Biome} ({Danger})", iterations, biome, danger);

        var stats = new LootStatistics();
        var context = new LootGenerationContext(biome, danger, null, 0); // No Wits bonus for baseline

        // Parallel processing for speed on high iteration counts
        Parallel.For(0, iterations, _ =>
        {
            // Note: LootService must be thread-safe (Random instance handling)
            var result = _lootService.GenerateLoot(context);
            lock (stats)
            {
                stats.Record(result);
            }
        });

        return GenerateMarkdownReport(stats, biome, danger);
    }

    private string GenerateMarkdownReport(LootStatistics stats, BiomeType biome, DangerLevel danger)
    {
        var sb = new StringBuilder();
        sb.AppendLine($"# Loot Audit Report");
        sb.AppendLine($"**Date:** {DateTime.Now} | **Iterations:** {stats.TotalIterations}");
        sb.AppendLine($"**Biome:** {biome} | **Danger:** {danger}");
        sb.AppendLine($"**Avg Value per Drop:** {stats.TotalScripValue / (double)stats.TotalIterations:F2} Scrip");

        sb.AppendLine("\n## Rarity Distribution");
        sb.AppendLine("| Rarity | Count | Frequency | Expected | Variance |");
        sb.AppendLine("|---|---|---|---|---|");

        // ... Table generation logic comparing stats.RarityCounts to LootTables.ExpectedRates ...

        return sb.ToString();
    }
}

5. Logging Requirements
System
Event
Level
Message Template
Properties
Audit
Start
Info
"Starting Loot Audit: {Iterations} cycles."
Iterations
Audit
Progress
Debug
"Completed {Count}/{Total} cycles."
Count, Total
Audit
Anomaly
Warning
"Anomaly detected: {Item} dropped in {Danger} zone."
Item, Danger
Audit
Complete
Info
"Audit complete. Report written to {Path}."
Path

6. Testing Strategy
	•	Unit Test (LootStatisticsTests.cs):
	◦	Record_AccumulatesValuesCorrectly: Feed known results, verify Totals match.
	◦	Record_HandlesEmptyResults: Verify TotalIterations increments even if no items drop.
	•	Integration Test (LootAuditIntegrationTests.cs):
	◦	Sanity Check: Run 100 iterations. Assert TotalItemsDropped > 0. Assert TotalScripValue > 0.
	◦	Probability Bounds: Run 10,000 iterations (Safe Zone). Assert MythForged count is 0 (or statistically near-zero).

7. Draft Changelog (v0.3.13a)
# v0.3.13a Changelog: The Loot Audit
**Release Date:** 2026-01-20

## Summary
This release introduces the `audit-loot` tool, a Monte Carlo simulation engine for verifying the game's economy. Developers can now run thousands of loot generation cycles instantly to ensure drop rates match design intentions before players encounter them.

## New Features
*   **Loot Audit Tool:** A CLI utility that simulates chest openings and generates statistical reports.
*   **Variance Reporting:** Automatically flags if drop rates deviate significantly from expected values.
*   **Economic Balancing:** Tuned `LootTables` based on initial audit results to prevent inflation in early zones.

## Technical Changes
*   Implemented `LootAuditService` in Engine.
*   Added `LootStatistics` data model.
*   Updated `Program.cs` to handle the `--audit-loot` flag.
*   Ensured `DiceService` and `LootService` are thread-safe for parallel simulation.
